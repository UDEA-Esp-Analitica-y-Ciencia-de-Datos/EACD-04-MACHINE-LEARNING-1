{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/UDEA-Esp-Analitica-y-Ciencia-de-Datos/EACD-04-MACHINE-LEARNING-1/blob/master/02-%5BTALLER%5D_Script_basico_de_una_simulacion_en_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras alamancenar tu progreso**\n",
    "\n",
    "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué se debe considerar en una simulación de ML?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget --no-cache -O init.py -q https://raw.githubusercontent.com/UDEA-Esp-Analitica-y-Ciencia-de-Datos/EACD-04-MACHINE-LEARNING-1/master/init.py\n",
    "import init; init.init(force_download=False); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='teal'>**Elementos a considerar**:</font>\n",
    "\n",
    "- <font color=#666666>**Comprender el problema!**:</font>\n",
    "- Carga de datos\n",
    "- Tamaño de la base de datos\n",
    "- Tipos de fuentes de información (formularios, imágenes, texto, audio, series de tiempo, etc.)\n",
    "- Preprocesemanieto, segmentación, filtrado.\n",
    "- Codificación de variables: \n",
    "    - Catergóricas\n",
    "    - Contínuas\n",
    "    - Discretas\n",
    "- Limpieza, imputación.\n",
    "- Estandarización de variables\n",
    "- Selección/extracción de características\n",
    "- Métricas de evaluación \n",
    "- Metodologías de validación: considerar tipo de problema, distribución de clases en la BD, volúmen.\n",
    "- Modelos a evaluar\n",
    "- Hiperparámetros de los modelos y de los algoritmos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este ejercicio vamos a usar la **Breast cancer wisconsin (diagnostic) dataset** que puede ser descargada del UCI Machine Learning Repository [link](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tamaño de la base de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((569, 30), (569,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape, data.target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown  ¿Cuál es el contexto del problema?\n",
    "respuesta_1 = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown  ¿Cuál es el problema que se debe resolver desde el punto de vista de Machine Learning?\n",
    "respuesta_2 = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Características**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(6,5, figsize=(15,20))\n",
    "f = 0\n",
    "for i in range(6):\n",
    "    for j in range(5):\n",
    "        axs[i,j].hist(data.data[data.target==0,f],30,alpha=0.5, label='Class 0')\n",
    "        axs[i,j].hist(data.data[data.target==1,f],30,alpha=0.5, label='Class 1')\n",
    "        axs[i,j].set_title(data.feature_names[f])\n",
    "        axs[i,j].legend()\n",
    "        f += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metodología de Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estandarización de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo base e hiperparámetros a evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[the k-nearest neighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Hiperparámetros?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métrica de evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conjunto de hiperparámetros a evaluar\n",
    "grid_search = [1,3,5,7,9]\n",
    "\n",
    "#variables para almacenar los valores de las medidas de desempeño\n",
    "Train_Error = []\n",
    "Test_Error = []\n",
    "for i in grid_search:\n",
    "    #Instanciar y entrenar el mdoelo\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(X_train,y_train)\n",
    "    \n",
    "    #Estimar las medidas de desempeño\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    Train_Error.append(accuracy_score(y_train,y_pred_train))\n",
    "    Test_Error.append(accuracy_score(y_test,y_pred_test))\n",
    "\n",
    "Train_Error = np.array(Train_Error)\n",
    "Test_Error = np.array(Test_Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(grid_search,Train_Error, label='Train Accuracy')\n",
    "plt.plot(grid_search,Test_Error, label='Test Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown  ¿Cuál es el mejor valor para el hiperparámetro del modelo?\n",
    "respuesta_3 = \"\" #@param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Pregunta Abierta\n",
    "#@markdown  ¿Qué es un pipeline en Machine Learning?\n",
    "respuesta_4 = \"\" #@param {type:\"string\"}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
